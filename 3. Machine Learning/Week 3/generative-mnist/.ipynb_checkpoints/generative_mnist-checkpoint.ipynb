{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian generative models for handwritten digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the 1-NN classifier yielded a 3.09% test error rate on the MNIST data set of handwritten digits. We will now see that a Gaussian generative model does almost as well, while being significantly faster and more compact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up notebook and load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing the required packages and data. For this notebook we will be using the *entire* `MNIST` dataset. The code below defines some helper functions that will load `MNIST` onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import gzip, os\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import sys\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **displaychar** shows a single MNIST digit. To do this, it first has to reshape the 784-dimensional vector into a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABWxJREFUeJzt3S+LlVsfgOGzDwcH0aAgThGr3TzKpLEpIugH0GIwWSwW\nQRGb1TJRsFoMijgYpwiCH8AkGkQEg+LzlvOml1nvOH/2jN7XVX/72WuVmxXW7Gdm0zT9BfT8vdcb\nAPaG+CFK/BAlfogSP0SJH6LED1HihyjxQ9Q/81xsNpv5c0LYZdM0zTbzOSc/RIkfosQPUeKHKPFD\nlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/\nRIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CHqn73eAH+227dvbzi7c+fO8Nm3\nb98O5/fu3RvOHz9+PJzXOfkhSvwQJX6IEj9EiR+ixA9R4oeo2TRN81tsNpvfYvvI3bt3h/MnT54M\n52/evNnJ7eyohYWF4fzTp08bzg4dOrSttdfW1obz5eXlbX3/72qaptlmPufkhyjxQ5T4IUr8ECV+\niBI/RPlJ7yYdPXp0w9n58+eHz16/fn04v3bt2nB+4sSJ4fz79+/D+V7a7nUeu8fJD1HihyjxQ5T4\nIUr8ECV+iBI/RLnn36RTp05tOFtdXd3VtWezTf1CE36Jkx+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6I8t7+38C5c+eG86dPn85p\nJ/xJnPwQJX6IEj9EiR+ixA9R4ocoV32btLS0tGdr37x5czh/+fLlhrOvX78On7148eJwfvLkyeH8\nwoULwzn7l5MfosQPUeKHKPFDlPghSvwQJX6Imk3TNL/FZrP5LbbDXr16teHszJkzc9zJ//rw4cOG\nsx8/fgyfPXbs2HC+sLCwpT3Nw8rKynD+/PnzOe1kf5mmabaZzzn5IUr8ECV+iBI/RIkfosQPUeKH\nKL/n/9fZs2eH89OnT89pJ79ucXFxr7ewJ758+bLXW/itOfkhSvwQJX6IEj9EiR+ixA9R4oco9/z/\nevfu3XD++vXrDWf/719oszWfP38ezo8cOTKnnfyZnPwQJX6IEj9EiR+ixA9R4oco8UOU9/Zv0uj9\n9leuXBk+e+vWrZ3ezo559OjRcP7x48fh/MGDB8P54cOHf3lP//X+/fvhfH19fTi/dOnSltf+nXlv\nPzAkfogSP0SJH6LED1HihyhXfWzLw4cPh/MbN27s2tpra2vD+fLy8q6tvZ+56gOGxA9R4oco8UOU\n+CFK/BAlfojy6m625cWLF8P5bt7zsz1OfogSP0SJH6LED1HihyjxQ5T4Ico9P9uytLS011tgi5z8\nECV+iBI/RIkfosQPUeKHKPFDlHt+tmVhYWGvt8AWOfkhSvwQJX6IEj9EiR+ixA9RrvoYOn78+HB+\n+fLlOe2EnebkhyjxQ5T4IUr8ECV+iBI/RIkfotzzM3TgwIHhfHFxcU47Yac5+SFK/BAlfogSP0SJ\nH6LED1Hihyj3/Az9/PlzOP/27dtwfvDgwS2vvb6+Ppzfv39/y9+Nkx+yxA9R4oco8UOU+CFK/BAl\nfoiaTdM0v8Vms/ktxlysrKwM58+ePdvyd1+9enU4X11d3fJ3/8mmaZpt5nNOfogSP0SJH6LED1Hi\nhyjxQ5T4Ico9P/xh3PMDQ+KHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJ\nH6LED1HihyjxQ5T4IUr8ECV+iJrrq7uB/cPJD1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFD\nlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0T9B27TpGu74pqnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1197c5048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displaychar(train_data[58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of 60,000 images. Thus `train_data` should be a 60000x784 array while `train_labels` should be 60000x1. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"magenta\">For you to do:</font>** Define a function, **fit_generative_model**, that takes as input a training set (data `x` and labels `y`) and fits a Gaussian generative model to it. It should return the parameters of this generative model; for each label `j = 0,1,...,9`, we have:\n",
    "* `pi[j]`: the frequency of that label\n",
    "* `mu[j]`: the 784-dimensional mean vector\n",
    "* `sigma[j]`: the 784x784 covariance matrix\n",
    "\n",
    "This means that `pi` is 10x1, `mu` is 10x784, and `sigma` is 10x784x784.\n",
    "\n",
    "We have already seen how to fit a Gaussian generative model in the Winery example, but now there is an added ingredient. <font color=\"magenta\">The empirical covariances are very likely to be singular (or close to singular), which means that we won't be able to do calculations with them</font>. Thus it is important to **regularize** these matrices. The standard way of doing this is to add `cI` to them, where `c` is some constant and `I` is the 784-dimensional identity matrix. (To put it another way, we compute the empirical covariances and then increase their diagonal entries by some constant `c`.)\n",
    "\n",
    "This modification is guaranteed to yield covariance matrices that are non-singular, for any `c > 0`, no matter how small. But this doesn't mean that we should make `c` as small as possible. Indeed, `c` is now a parameter, and by setting it appropriately, we can improve the performance of the model. We will study **regularization** in greater detail over the coming weeks.\n",
    "\n",
    "Your routine needs to choose a good setting of `c`. Crucially, this needs to be done using the training set alone. So you might try setting aside part of the training set as a validation set, or using some kind of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y, c = 10):\n",
    "    k = 10  # labels 0,1,...,k-1\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    n = y.shape[0]\n",
    "    for label in range(k):\n",
    "        this_label_samples = x[y == label]\n",
    "        mu[label,:] = np.mean(this_label_samples, axis = 0)\n",
    "        pi[label] = this_label_samples.shape[0] / n\n",
    "        sigma[label] = np.cov(this_label_samples, rowvar = 0, bias = 1) + np.eye(x.shape[1]) * c\n",
    "\n",
    "    # Halt and return parameters\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's try out your function. In particular, we will use **displaychar** to visualize the means of the Gaussians for the first three digits. You can try the other digits on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120ebb3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma, pi = fit_generative_model(train_data, train_labels, c =4000)\n",
    "displaychar(mu[0])\n",
    "displaychar(mu[1])\n",
    "displaychar(mu[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many errors your model makes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log Pr(label|image) for each [test image,label] pair.\n",
    "k = 10\n",
    "score = np.zeros((len(test_labels),k))\n",
    "for label in range(0,k):\n",
    "    rv = multivariate_normal(mean=mu[label], cov=sigma[label])\n",
    "    for i in range(0,len(test_labels)):\n",
    "       score[i,label] = np.log(pi[label]) + rv.logpdf(test_data[i,:])\n",
    "predictions = np.argmax(score, axis=1)\n",
    "# Finally, tally up score\n",
    "errors = np.sum(predictions != test_labels)\n",
    "print(\"Your model makes \" + str(errors) + \" errors out of 10000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You will need to answer variants of these questions as part of this week's assignment*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 1:</font> What happens if you do not regularize the covariance matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 2:</font> What happens if you set the value of `c` too high, for instance to one billion? Do you understand why this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 3:</font> What value of c did you end up using? How many errors did your model make on the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">If you have the time</font>: We have talked about using the same regularization constant `c` for all ten classes. What about using a different value of `c` for each class? How would you go about choosing these? Can you get better performance in this way?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
